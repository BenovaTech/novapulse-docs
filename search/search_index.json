{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NovaPulse Documentation","text":"<p>NovaPulse is an AI-powered Voice Analytics Platform that transforms raw audio conversations into structured, actionable intelligence. Built for enterprise teams in customer support, sales, HR, and healthcare, NovaPulse delivers transcription, sentiment analysis, speaker diarization, and autonomous voice agent capabilities through a single REST API.</p>"},{"location":"#quick-navigation","title":"Quick navigation","text":"New to NovaPulseBuilding with the APIUnderstanding the platform <p>Start here if you're integrating NovaPulse for the first time.</p> <ol> <li>Read the Platform Overview    to understand what NovaPulse does and how it's structured.</li> <li>Follow the Getting Started tutorial    to make your first API call in under 10 minutes.</li> <li>Explore the API Reference for complete    endpoint documentation.</li> </ol> <p>For developers actively integrating NovaPulse.</p> <ul> <li>Authentication \u2014 API keys and headers</li> <li>Audio Ingestion API \u2014 Upload audio files</li> <li>Transcription API \u2014 Retrieve transcripts</li> <li>Sentiment Analysis API \u2014 Query insights</li> </ul> <p>Conceptual guides for deeper understanding.</p> <ul> <li>Vector Search in NovaPulse</li> <li>RAG Pipeline architecture</li> <li>NLP capabilities</li> <li>System architecture</li> </ul>"},{"location":"#platform-capabilities","title":"Platform capabilities","text":"Capability Description Phase Transcription Speaker-attributed text from audio with \u226590% accuracy GA Sentiment analysis Per-segment sentiment scoring and trend detection GA Speaker diarization Automatic speaker identification and labeling GA PII redaction Automated detection and redaction of personal data GA Real-time analytics Live audio stream processing with \u22642s latency Beta Autonomous agents Context-aware AI voice agents for full conversations Planned"},{"location":"#documentation-status","title":"Documentation status","text":"Section Status Last updated API Reference  Complete 2025-05-01 Tutorials  Complete 2025-05-01 Concepts  Complete 2025-05-01 Architecture  Complete 2025-05-01 Reference  Complete 2025-05-01 Release Notes  Complete 2025-05-01 <p>About this documentation</p> <p>This documentation site is a portfolio project demonstrating technical writing methodology for an AI SaaS platform. Built with MkDocs Material, deployed via GitHub Actions, and maintained using a docs-as-code workflow. \u2014 Houda Benlemmouden</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>The NovaPulse API is a REST API that accepts JSON request bodies and returns JSON responses. All requests must be authenticated using an API key.</p> <p>Base URL: <code>https://api.novapulse.io/v1</code></p>"},{"location":"api-reference/#authentication","title":"Authentication","text":"<p>All endpoints require a Bearer token in the <code>Authorization</code> header:</p> <pre><code>Authorization: Bearer nvp_live_YOUR_API_KEY\n</code></pre> <p>See Authentication for full details.</p>"},{"location":"api-reference/#endpoints","title":"Endpoints","text":"Endpoint Method Description <code>/v1/audio/ingest</code> POST Upload an audio file for processing <code>/v1/jobs/{job_id}</code> GET Check processing job status <code>/v1/transcriptions/{job_id}</code> GET Retrieve transcript and diarization results <code>/v1/insights/{job_id}</code> GET Retrieve sentiment analysis and behavioral metrics"},{"location":"api-reference/#request-and-response-format","title":"Request and response format","text":"<p>All request bodies must be sent as <code>multipart/form-data</code> (for file uploads) or <code>application/json</code>. All responses are returned as <code>application/json</code> unless an alternative format is requested via query parameter.</p>"},{"location":"api-reference/#error-format","title":"Error format","text":"<p>All error responses follow a consistent structure:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"invalid_api_key\",\n    \"message\": \"The API key provided is invalid or has been revoked.\",\n    \"status\": 401\n  }\n}\n</code></pre> <p>See Error codes for the full list.</p>"},{"location":"api-reference/#rate-limits","title":"Rate limits","text":"<p>All endpoints are rate-limited per API key. See Rate limits for thresholds and retry guidance.</p>"},{"location":"api-reference/#api-versioning","title":"API versioning","text":"<p>The current stable version is <code>v1</code>. Breaking changes will not be introduced without a version increment and a minimum 90-day deprecation notice.</p>"},{"location":"api-reference/audio-ingestion/","title":"Audio Ingestion API","text":"<p>Upload an audio file to NovaPulse to begin the processing pipeline. The API accepts audio files in multiple formats, validates the upload, stores the file securely, and returns a job ID for tracking.</p>"},{"location":"api-reference/audio-ingestion/#endpoint","title":"Endpoint","text":"<p>POST <code>/v1/audio/ingest</code></p>"},{"location":"api-reference/audio-ingestion/#prerequisites","title":"Prerequisites","text":"<ul> <li>A valid API key with <code>audio:write</code> permission</li> <li>Audio file in a supported format (see Supported formats)</li> <li>File size must not exceed 500 MB</li> </ul>"},{"location":"api-reference/audio-ingestion/#request","title":"Request","text":"<p>Send the request as <code>multipart/form-data</code>.</p>"},{"location":"api-reference/audio-ingestion/#form-fields","title":"Form fields","text":"Field Type Required Description <code>file</code> binary Yes The audio file to upload. <code>language</code> string No BCP-47 language tag. Default: <code>en-US</code>. <code>pipeline</code> string No Processing pipeline. One of: <code>transcription</code>, <code>full-analysis</code>. Default: <code>full-analysis</code>. <code>metadata</code> JSON string No Optional key-value pairs attached to the job (e.g. <code>{\"agent_id\": \"AGT-42\"}</code>). <code>webhook_url</code> string No HTTPS URL to notify when processing completes."},{"location":"api-reference/audio-ingestion/#pipeline-values","title":"Pipeline values","text":"Value What runs <code>transcription</code> Transcription and speaker diarization only. Faster and lower cost. <code>full-analysis</code> Transcription + diarization + sentiment analysis + summarization + PII detection."},{"location":"api-reference/audio-ingestion/#supported-formats","title":"Supported formats","text":"Format Extension Max sample rate MP3 <code>.mp3</code> 48 kHz WAV <code>.wav</code> 96 kHz M4A <code>.m4a</code> 48 kHz FLAC <code>.flac</code> 96 kHz OGG <code>.ogg</code> 48 kHz"},{"location":"api-reference/audio-ingestion/#request-example","title":"Request example","text":"cURLPython <pre><code>curl -X POST https://api.novapulse.io/v1/audio/ingest \\\n  -H 'Authorization: Bearer nvp_live_abc123...' \\\n  -F 'file=@/path/to/call-recording.mp3' \\\n  -F 'pipeline=full-analysis' \\\n  -F 'language=en-US' \\\n  -F 'metadata={\"agent_id\": \"AGT-42\", \"call_type\": \"support\"}'\n</code></pre> <pre><code>import requests\nimport json\n\nurl = 'https://api.novapulse.io/v1/audio/ingest'\nheaders = {'Authorization': 'Bearer nvp_live_abc123...'}\n\nwith open('/path/to/call-recording.mp3', 'rb') as audio_file:\n    files = {'file': ('call-recording.mp3', audio_file, 'audio/mpeg')}\n    data = {\n        'pipeline': 'full-analysis',\n        'language': 'en-US',\n        'metadata': json.dumps({'agent_id': 'AGT-42'})\n    }\n    response = requests.post(url, headers=headers, files=files, data=data)\n\nprint(response.json())\n</code></pre>"},{"location":"api-reference/audio-ingestion/#response","title":"Response","text":"<p>Returns <code>202 Accepted</code> immediately. Processing happens asynchronously.</p> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"status\": \"queued\",\n  \"pipeline\": \"full-analysis\",\n  \"created_at\": \"2025-04-15T14:32:00Z\",\n  \"estimated_completion\": \"2025-04-15T14:34:00Z\",\n  \"file\": {\n    \"name\": \"call-recording.mp3\",\n    \"size_bytes\": 4823041,\n    \"duration_seconds\": 312\n  }\n}\n</code></pre>"},{"location":"api-reference/audio-ingestion/#response-fields","title":"Response fields","text":"Field Type Description <code>job_id</code> string Unique identifier for this processing job. Use this to poll status. <code>status</code> string Initial status. Always <code>queued</code> on creation. <code>pipeline</code> string The pipeline requested. <code>created_at</code> string (ISO 8601) Timestamp when the job was created. <code>estimated_completion</code> string (ISO 8601) Estimated time when results will be available. <code>file.name</code> string Original filename as uploaded. <code>file.size_bytes</code> integer File size in bytes. <code>file.duration_seconds</code> integer Audio duration detected at upload time."},{"location":"api-reference/audio-ingestion/#response-codes","title":"Response codes","text":"Code Meaning <code>202 Accepted</code> Upload successful. Job has been queued. <code>400 Bad Request</code> Missing required field or invalid parameter. <code>401 Unauthorized</code> Invalid or missing API key. <code>413 Payload Too Large</code> File exceeds 500 MB limit. <code>415 Unsupported Media Type</code> Audio format not supported. <code>429 Too Many Requests</code> Rate limit exceeded. See Rate limits."},{"location":"api-reference/audio-ingestion/#polling-for-job-status","title":"Polling for job status","text":"<p>After upload, poll <code>GET /v1/jobs/{job_id}</code> to check processing status:</p> <pre><code>curl https://api.novapulse.io/v1/jobs/job_9f3c2a1b4e7d \\\n  -H 'Authorization: Bearer nvp_live_abc123...'\n</code></pre> <p>Job status transitions: <code>queued</code> \u2192 <code>processing</code> \u2192 <code>completed</code> or <code>failed</code></p>"},{"location":"api-reference/audio-ingestion/#related","title":"Related","text":"<ul> <li>Transcription API \u2014 Retrieve transcript results</li> <li>Sentiment Analysis API \u2014 Retrieve sentiment data</li> <li>Getting Started tutorial</li> </ul>"},{"location":"api-reference/authentication/","title":"Authentication","text":"<p>The NovaPulse API uses API key authentication. Include your API key as a Bearer token in the <code>Authorization</code> header of every request.</p>"},{"location":"api-reference/authentication/#obtain-an-api-key","title":"Obtain an API key","text":"<ol> <li>Log in to the NovaPulse dashboard.</li> <li>Navigate to Settings \u2192 API Keys.</li> <li>Click Generate new key.</li> <li>Copy the key immediately \u2014 it is shown only once.</li> </ol> <p>Keep your API key secure</p> <p>Never commit API keys to source control or expose them in client-side code. Use environment variables or a secrets manager.</p>"},{"location":"api-reference/authentication/#authentication-header","title":"Authentication header","text":"<p>Include your key in every API request:</p> <pre><code>Authorization: Bearer nvp_live_YOUR_API_KEY_HERE\n</code></pre>"},{"location":"api-reference/authentication/#request-examples","title":"Request examples","text":"cURLPythonJavaScript <pre><code>curl -X GET https://api.novapulse.io/v1/jobs \\\n  -H 'Authorization: Bearer nvp_live_abc123...' \\\n  -H 'Content-Type: application/json'\n</code></pre> <pre><code>import requests\n\nheaders = {\n    'Authorization': 'Bearer nvp_live_abc123...',\n    'Content-Type': 'application/json'\n}\n\nresponse = requests.get('https://api.novapulse.io/v1/jobs', headers=headers)\n</code></pre> <pre><code>const response = await fetch('https://api.novapulse.io/v1/jobs', {\n  headers: {\n    'Authorization': 'Bearer nvp_live_abc123...',\n    'Content-Type': 'application/json'\n  }\n});\n</code></pre>"},{"location":"api-reference/authentication/#authentication-errors","title":"Authentication errors","text":"HTTP status Error code Description <code>401 Unauthorized</code> <code>invalid_api_key</code> The key is missing or malformed. <code>401 Unauthorized</code> <code>expired_api_key</code> The key has been revoked or expired. <code>403 Forbidden</code> <code>insufficient_permissions</code> The key doesn't have access to this resource."},{"location":"api-reference/authentication/#api-key-prefixes","title":"API key prefixes","text":"<p>NovaPulse API keys use a prefix to distinguish environment:</p> Prefix Environment Use for <code>nvp_live_</code> Production Live data and real integrations <code>nvp_test_</code> Sandbox Development and testing \u2014 no charges"},{"location":"api-reference/authentication/#related","title":"Related","text":"<ul> <li>Rate limits</li> <li>Error codes reference</li> <li>Getting started tutorial</li> </ul>"},{"location":"api-reference/sentiment-analysis/","title":"Sentiment Analysis API","text":"<p>Retrieve sentiment analysis results for a completed audio job. NovaPulse's sentiment engine scores each transcript segment on a continuous scale and produces an overall call sentiment classification, trend data, and behavioral signals such as silence ratio and interruption count.</p> <p>Sentiment analysis is available when the job was processed with <code>pipeline=full-analysis</code>.</p>"},{"location":"api-reference/sentiment-analysis/#endpoint","title":"Endpoint","text":"<p>GET <code>/v1/insights/{job_id}</code></p>"},{"location":"api-reference/sentiment-analysis/#prerequisites","title":"Prerequisites","text":"<ul> <li>A valid API key with <code>insights:read</code> permission</li> <li>A completed job processed with <code>pipeline=full-analysis</code></li> </ul>"},{"location":"api-reference/sentiment-analysis/#path-parameters","title":"Path parameters","text":"Parameter Type Required Description <code>job_id</code> string Yes The job ID returned by <code>POST /v1/audio/ingest</code>."},{"location":"api-reference/sentiment-analysis/#query-parameters","title":"Query parameters","text":"Parameter Type Default Description <code>type</code> string <code>all</code> Insight type to return. One of: <code>sentiment</code>, <code>behavioral</code>, <code>summary</code>, <code>all</code>. <code>speaker</code> string \u2014 Filter results to a specific speaker. Values: <code>Agent</code>, <code>Customer</code>. <code>granularity</code> string <code>segment</code> Sentiment resolution. One of: <code>segment</code>, <code>minute</code>, <code>call</code>."},{"location":"api-reference/sentiment-analysis/#request-example","title":"Request example","text":"cURL \u2014 sentiment onlycURL \u2014 customer sentiment onlyPython <pre><code>curl \"https://api.novapulse.io/v1/insights/job_9f3c2a1b4e7d?type=sentiment\" \\\n  -H \"Authorization: Bearer nvp_live_abc123...\"\n</code></pre> <pre><code>curl \"https://api.novapulse.io/v1/insights/job_9f3c2a1b4e7d?type=sentiment&amp;speaker=Customer\" \\\n  -H \"Authorization: Bearer nvp_live_abc123...\"\n</code></pre> <pre><code>import requests\n\njob_id = \"job_9f3c2a1b4e7d\"\nurl = f\"https://api.novapulse.io/v1/insights/{job_id}\"\nheaders = {\"Authorization\": \"Bearer nvp_live_abc123...\"}\nparams = {\"type\": \"all\", \"speaker\": \"Customer\"}\n\nresponse = requests.get(url, headers=headers, params=params)\ninsights = response.json()\n\nprint(f\"Overall sentiment: {insights['sentiment']['overall_label']}\")\nprint(f\"Score: {insights['sentiment']['overall_score']}\")\n</code></pre>"},{"location":"api-reference/sentiment-analysis/#response","title":"Response","text":"<p>Returns <code>200 OK</code> with the full insights object.</p> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"pipeline\": \"full-analysis\",\n  \"sentiment\": {\n    \"overall_label\": \"negative\",\n    \"overall_score\": -0.68,\n    \"trend\": \"declining\",\n    \"segments\": [\n      {\n        \"segment_id\": 1,\n        \"speaker\": \"Agent\",\n        \"start\": 0.0,\n        \"end\": 4.2,\n        \"label\": \"neutral\",\n        \"score\": 0.05\n      },\n      {\n        \"segment_id\": 2,\n        \"speaker\": \"Customer\",\n        \"start\": 4.5,\n        \"end\": 11.8,\n        \"label\": \"negative\",\n        \"score\": -0.82\n      },\n      {\n        \"segment_id\": 3,\n        \"speaker\": \"Agent\",\n        \"start\": 12.1,\n        \"end\": 18.4,\n        \"label\": \"neutral\",\n        \"score\": 0.12\n      }\n    ]\n  },\n  \"behavioral\": {\n    \"silence_ratio\": 0.08,\n    \"interruption_count\": 3,\n    \"agent_talk_ratio\": 0.52,\n    \"customer_talk_ratio\": 0.40,\n    \"average_response_time_seconds\": 1.4\n  },\n  \"summary\": \"Customer called to cancel subscription due to pricing concerns. Agent attempted retention. No resolution reached \u2014 escalation recommended.\",\n  \"recommendations\": [\n    \"Escalate to retention specialist \u2014 high churn risk detected.\",\n    \"Review pricing communication \u2014 customer unaware of discount options.\",\n    \"Agent response time within acceptable range.\"\n  ]\n}\n</code></pre>"},{"location":"api-reference/sentiment-analysis/#response-fields","title":"Response fields","text":""},{"location":"api-reference/sentiment-analysis/#top-level","title":"Top-level","text":"Field Type Description <code>job_id</code> string The job identifier. <code>pipeline</code> string The pipeline used. Sentiment data requires <code>full-analysis</code>. <code>sentiment</code> object Sentiment analysis results. See Sentiment object. <code>behavioral</code> object Behavioral metrics. See Behavioral object. <code>summary</code> string AI-generated call summary. <code>recommendations</code> array Actionable recommendations generated from the call analysis."},{"location":"api-reference/sentiment-analysis/#sentiment-object","title":"Sentiment object","text":"Field Type Description <code>overall_label</code> string Overall call sentiment. One of: <code>positive</code>, <code>neutral</code>, <code>negative</code>. <code>overall_score</code> float Aggregate sentiment score from -1.0 (most negative) to +1.0 (most positive). <code>trend</code> string Sentiment direction across the call. One of: <code>improving</code>, <code>stable</code>, <code>declining</code>. <code>segments</code> array Per-segment sentiment. See Sentiment segment."},{"location":"api-reference/sentiment-analysis/#sentiment-segment","title":"Sentiment segment","text":"Field Type Description <code>segment_id</code> integer References the <code>id</code> field in the transcript segment. <code>speaker</code> string Speaker label for this segment. <code>start</code> float Segment start time in seconds. <code>end</code> float Segment end time in seconds. <code>label</code> string Sentiment classification for this segment. <code>score</code> float Sentiment score for this segment (-1.0 to +1.0)."},{"location":"api-reference/sentiment-analysis/#behavioral-object","title":"Behavioral object","text":"Field Type Description <code>silence_ratio</code> float Proportion of the call spent in silence (0.0\u20131.0). High values may indicate confusion or hold time. <code>interruption_count</code> integer Number of times either speaker interrupted the other. <code>agent_talk_ratio</code> float Proportion of speaking time attributed to the agent. <code>customer_talk_ratio</code> float Proportion of speaking time attributed to the customer. <code>average_response_time_seconds</code> float Mean time between one speaker finishing and the other beginning."},{"location":"api-reference/sentiment-analysis/#sentiment-score-reference","title":"Sentiment score reference","text":"Score range Label Interpretation +0.5 to +1.0 <code>positive</code> Customer is satisfied, engaged, or pleased -0.4 to +0.5 <code>neutral</code> No strong emotional signal detected -1.0 to -0.4 <code>negative</code> Customer is frustrated, dissatisfied, or at churn risk"},{"location":"api-reference/sentiment-analysis/#response-codes","title":"Response codes","text":"Code Meaning <code>200 OK</code> Insights retrieved successfully. <code>400 Bad Request</code> Invalid <code>type</code> or <code>granularity</code> parameter. <code>401 Unauthorized</code> Invalid or missing API key. <code>403 Forbidden</code> Insufficient permissions or job processed without <code>full-analysis</code>. <code>404 Not Found</code> Job ID not found or still processing. <code>429 Too Many Requests</code> Rate limit exceeded. <p>Using sentiment for real-time alerting</p> <p>In Phase 2, NovaPulse will expose sentiment scores via a streaming endpoint for live calls. Supervisors will be able to trigger interventions when a customer's sentiment score drops below a configurable threshold during an active conversation.</p>"},{"location":"api-reference/sentiment-analysis/#related","title":"Related","text":"<ul> <li>Transcription API \u2014 Retrieve the full transcript</li> <li>Audio Ingestion API \u2014 Upload audio files</li> <li>Getting Started tutorial</li> <li>Glossary \u2014 Sentiment analysis</li> </ul>"},{"location":"api-reference/transcription/","title":"Transcription API","text":"<p>Retrieve the transcript generated from a processed audio file. Transcripts include speaker-attributed segments with timestamps, confidence scores, and word-level detail. Transcription is available after the job status is <code>completed</code>.</p>"},{"location":"api-reference/transcription/#endpoint","title":"Endpoint","text":"<p>GET <code>/v1/transcriptions/{job_id}</code></p>"},{"location":"api-reference/transcription/#prerequisites","title":"Prerequisites","text":"<ul> <li>A valid API key with <code>transcription:read</code> permission</li> <li>A completed job ID from the Audio Ingestion API</li> <li>Job status must be <code>completed</code> \u2014 polling a job still in <code>processing</code> returns <code>404</code></li> </ul>"},{"location":"api-reference/transcription/#path-parameters","title":"Path parameters","text":"Parameter Type Required Description <code>job_id</code> string Yes The job ID returned by <code>POST /v1/audio/ingest</code>."},{"location":"api-reference/transcription/#query-parameters","title":"Query parameters","text":"Parameter Type Default Description <code>format</code> string <code>json</code> Response format. One of: <code>json</code>, <code>srt</code>, <code>vtt</code>, <code>txt</code>. <code>speaker_labels</code> boolean <code>true</code> Include speaker labels in the response. Set to <code>false</code> for raw transcript only. <code>word_timestamps</code> boolean <code>false</code> Include per-word start and end timestamps. Increases response size significantly. <code>redact_pii</code> boolean <code>true</code> Return the redacted transcript. Set to <code>false</code> to retrieve the unredacted version (requires <code>pii:read</code> permission)."},{"location":"api-reference/transcription/#request-example","title":"Request example","text":"cURLcURL \u2014 SRT formatPython <pre><code>curl https://api.novapulse.io/v1/transcriptions/job_9f3c2a1b4e7d \\\n  -H \"Authorization: Bearer nvp_live_abc123...\"\n</code></pre> <pre><code>curl \"https://api.novapulse.io/v1/transcriptions/job_9f3c2a1b4e7d?format=srt\" \\\n  -H \"Authorization: Bearer nvp_live_abc123...\"\n</code></pre> <pre><code>import requests\n\njob_id = \"job_9f3c2a1b4e7d\"\nurl = f\"https://api.novapulse.io/v1/transcriptions/{job_id}\"\nheaders = {\"Authorization\": \"Bearer nvp_live_abc123...\"}\nparams = {\"word_timestamps\": True}\n\nresponse = requests.get(url, headers=headers, params=params)\ntranscript = response.json()\n</code></pre>"},{"location":"api-reference/transcription/#response","title":"Response","text":"<p>Returns <code>200 OK</code> with the transcript object.</p> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"status\": \"completed\",\n  \"language\": \"en-US\",\n  \"duration_seconds\": 312,\n  \"speakers_detected\": 2,\n  \"transcription_accuracy\": 0.94,\n  \"segments\": [\n    {\n      \"id\": 1,\n      \"speaker\": \"Agent\",\n      \"start\": 0.0,\n      \"end\": 4.2,\n      \"text\": \"Thank you for calling support. How can I help you today?\",\n      \"confidence\": 0.98\n    },\n    {\n      \"id\": 2,\n      \"speaker\": \"Customer\",\n      \"start\": 4.5,\n      \"end\": 11.8,\n      \"text\": \"I need to cancel my subscription. The pricing just doesn't work for us.\",\n      \"confidence\": 0.96\n    },\n    {\n      \"id\": 3,\n      \"speaker\": \"Agent\",\n      \"start\": 12.1,\n      \"end\": 18.4,\n      \"text\": \"I'm sorry to hear that. Can I ask what specifically isn't working for you?\",\n      \"confidence\": 0.97\n    }\n  ],\n  \"summary\": \"Customer called to cancel subscription due to pricing concerns. Agent attempted retention. No resolution reached \u2014 escalation recommended.\",\n  \"pii_redacted\": true,\n  \"created_at\": \"2025-04-15T14:32:00Z\",\n  \"completed_at\": \"2025-04-15T14:33:47Z\"\n}\n</code></pre>"},{"location":"api-reference/transcription/#response-fields","title":"Response fields","text":"Field Type Description <code>job_id</code> string The job identifier. <code>status</code> string Always <code>completed</code> when transcript is available. <code>language</code> string BCP-47 language tag detected or specified at upload. <code>duration_seconds</code> integer Total audio duration in seconds. <code>speakers_detected</code> integer Number of distinct speakers identified by diarization. <code>transcription_accuracy</code> float Aggregate confidence score across all segments (0.0\u20131.0). <code>segments</code> array Ordered list of transcript segments. See Segment object. <code>summary</code> string AI-generated conversation summary. Present only when <code>pipeline=full-analysis</code>. <code>pii_redacted</code> boolean Whether PII has been redacted in this response. <code>created_at</code> string ISO 8601 timestamp when the job was created. <code>completed_at</code> string ISO 8601 timestamp when processing finished."},{"location":"api-reference/transcription/#segment-object","title":"Segment object","text":"<p>Each object in the <code>segments</code> array represents a continuous speech segment attributed to a single speaker.</p> Field Type Description <code>id</code> integer Segment index, starting at 1. <code>speaker</code> string Speaker label. Values: <code>Agent</code>, <code>Customer</code>, or <code>Speaker N</code> for unlabeled speakers. <code>start</code> float Segment start time in seconds from the beginning of the audio. <code>end</code> float Segment end time in seconds. <code>text</code> string Transcribed text for this segment. PII is redacted if <code>pii_redacted</code> is <code>true</code>. <code>confidence</code> float Model confidence score for this segment (0.0\u20131.0). Segments below 0.75 may contain errors."},{"location":"api-reference/transcription/#export-formats","title":"Export formats","text":"Format Use case <code>json</code> Programmatic processing, integration with downstream systems <code>srt</code> Subtitle files for video players <code>vtt</code> Web Video Text Tracks \u2014 for use in HTML5 <code>&lt;video&gt;</code> elements <code>txt</code> Plain text, no timestamps or speaker labels"},{"location":"api-reference/transcription/#response-codes","title":"Response codes","text":"Code Meaning <code>200 OK</code> Transcript retrieved successfully. <code>401 Unauthorized</code> Invalid or missing API key. <code>403 Forbidden</code> Insufficient permissions. Check your key's scope. <code>404 Not Found</code> Job ID not found, or job is still processing. <code>429 Too Many Requests</code> Rate limit exceeded. <p>Speaker label accuracy</p> <p>Speaker labels (<code>Agent</code>, <code>Customer</code>) are assigned automatically based on conversation patterns. For calls with more than two speakers, labels appear as <code>Speaker 1</code>, <code>Speaker 2</code>, etc. Speaker enrollment for higher accuracy is planned for v1.2.</p>"},{"location":"api-reference/transcription/#related","title":"Related","text":"<ul> <li>Audio Ingestion API \u2014 Upload audio and get a job ID</li> <li>Sentiment Analysis API \u2014 Retrieve sentiment data for the same job</li> <li>Upload &amp; Analyze tutorial</li> <li>Error codes</li> </ul>"},{"location":"concepts/","title":"Concepts","text":"<p>These guides explain the core ideas behind NovaPulse. Read them to understand how the platform works before integrating the API.</p>"},{"location":"concepts/#in-this-section","title":"In this section","text":"Guide Description Platform Overview What NovaPulse is, its three phases, and who it's for Vector Search How NovaPulse uses semantic search across conversation data RAG Pipeline How retrieval-augmented generation powers AI-driven insights NLP Capabilities Transcription, diarization, sentiment, NER, and summarization"},{"location":"concepts/#new-to-novapulse","title":"New to NovaPulse?","text":"<p>Start with the Platform Overview to understand what NovaPulse does and how it's structured. Then follow the Getting Started tutorial to make your first API call.</p>"},{"location":"concepts/nlp-capabilities/","title":"NLP Capabilities","text":"<p>NovaPulse uses a pipeline of natural language processing (NLP) models to transform raw audio into structured data. Each capability runs automatically when you process audio with <code>pipeline=full-analysis</code>.</p>"},{"location":"concepts/nlp-capabilities/#automatic-speech-recognition-asr","title":"Automatic Speech Recognition (ASR)","text":"<p>ASR, also called transcription, converts spoken audio into text. NovaPulse's transcription engine is optimized for telephone-quality audio and multi-speaker conversations.</p> <p>Performance targets:</p> Condition Accuracy Clear audio, single speaker \u226596% Multi-speaker, standard quality \u226590% Background noise or heavy accent \u226582% <p>Accuracy is measured as word error rate (WER) against human-verified transcripts across a diverse test set.</p>"},{"location":"concepts/nlp-capabilities/#speaker-diarization","title":"Speaker Diarization","text":"<p>Diarization answers the question: who spoke when?</p> <p>NovaPulse's diarization engine segments the audio by speaker and assigns a consistent label to each speaker throughout the call : <code>Agent</code>, <code>Customer</code>, or <code>Speaker N</code> for calls with more than two participants.</p> <p>Diarization runs in parallel with transcription so that every transcript segment is speaker-attributed from the start.</p> <p>Note</p> <p>Speaker labels are assigned based on conversation patterns, not voice enrollment. For calls with very similar voice profiles, label accuracy may be lower. Voice enrollment for improved accuracy is planned for v1.2.</p>"},{"location":"concepts/nlp-capabilities/#sentiment-analysis","title":"Sentiment Analysis","text":"<p>NovaPulse scores each transcript segment on a continuous sentiment scale from -1.0 (strongly negative) to +1.0 (strongly positive), and produces an overall call sentiment classification.</p> <p>The sentiment model is trained on customer service conversation data and is optimized for detecting:</p> <ul> <li>Customer frustration and dissatisfaction</li> <li>Positive engagement and satisfaction signals</li> <li>Sentiment shifts during the conversation (trend detection)</li> <li>High-risk moments requiring supervisor intervention</li> </ul> <p>See Sentiment Analysis API for the full response schema.</p>"},{"location":"concepts/nlp-capabilities/#named-entity-recognition-ner","title":"Named Entity Recognition (NER)","text":"<p>NER identifies and classifies named entities in transcript text. NovaPulse uses NER for two purposes:</p> <p>PII detection: Identifies names, phone numbers, email addresses, account numbers, dates of birth, and other personally identifiable information so they can be automatically redacted before storage.</p> <p>Structured data extraction: Extracts business-relevant entities : product names, company names, locations, and dates, to enable downstream filtering and search.</p>"},{"location":"concepts/nlp-capabilities/#ai-summarization","title":"AI Summarization","text":"<p>NovaPulse generates a concise summary of each conversation automatically, covering:</p> <ul> <li>The primary reason for the call</li> <li>Key topics discussed</li> <li>Outcome or resolution status</li> <li>Recommended follow-up actions</li> </ul> <p>Summaries are generated using a large language model grounded in the actual transcript text not hallucinated. The transcript content is used as the context, ensuring the summary accurately reflects what was said.</p>"},{"location":"concepts/nlp-capabilities/#behavioral-analytics","title":"Behavioral Analytics","text":"<p>Beyond language, NovaPulse measures conversation dynamics:</p> Metric Description Silence ratio Proportion of the call spent in silence \u2014 high values indicate hold time or confusion Interruption count Number of times either speaker interrupted the other Talk ratio Proportion of speaking time per speaker \u2014 helps identify agent-dominated calls Average response time Mean time between speakers \u2014 long gaps may indicate confusion or hesitation"},{"location":"concepts/nlp-capabilities/#processing-pipeline","title":"Processing pipeline","text":"<p>When you upload audio with <code>pipeline=full-analysis</code>, NovaPulse runs these steps in sequence:</p> <pre><code>flowchart TD\n  A[Audio upload] --&gt; B[Audio validation &amp; format conversion]\n  B --&gt; C[ASR Transcription]\n  C --&gt; D[Speaker Diarization]\n  D --&gt; E[NER &amp; PII Detection]\n  E --&gt; F[Sentiment Analysis]\n  F --&gt; G[Behavioral Metrics]\n  G --&gt; H[AI Summarization]\n  H --&gt; I[Results stored &amp; available via API]\n\n  style A fill:#1B4F8A,color:#fff\n  style I fill:#155724,color:#fff</code></pre>"},{"location":"concepts/nlp-capabilities/#related","title":"Related","text":"<ul> <li>Platform Overview</li> <li>Vector Search \u2014 Semantic search across transcripts</li> <li>RAG Pipeline \u2014 AI-driven question answering</li> <li>Sentiment Analysis API</li> <li>Transcription API</li> </ul>"},{"location":"concepts/platform-overview/","title":"Platform Overview","text":"<p>NovaPulse is an AI Voice Agentic Infrastructure Platform that transforms raw audio conversations into structured, actionable intelligence. It is designed to integrate into enterprise business processes as foundational infrastructure and not as a point solution.</p>"},{"location":"concepts/platform-overview/#the-problem-novapulse-solves","title":"The problem NovaPulse solves","text":"<p>Organizations conduct thousands of voice conversations every day such as customer support calls, sales negotiations, HR interviews, compliance assessments. Each conversation carries significant strategic value: customer sentiment, compliance signals, sales opportunities, employee engagement indicators.</p> <p>Despite this, most organizations treat voice as transient. Recordings sit unused. Manual review is slow, inconsistent, and doesn't scale. Insights arrive days or weeks after the conversation, too late to act on.</p> <p>NovaPulse addresses this by treating voice as a structured, searchable, analyzable data source in real time.</p>"},{"location":"concepts/platform-overview/#three-phases-of-intelligence","title":"Three phases of intelligence","text":"<p>NovaPulse delivers its capabilities in three progressive phases:</p> <pre><code>flowchart LR\n  A[Phase 1 Structured Intelligence] --&gt; B[Phase 2 Real-Time Analytics] --&gt; C[Phase 3 Autonomous Voice Agents]\n\n  style A fill:#1B4F8A,color:#fff\n  style B fill:#1E6FD9,color:#fff\n  style C fill:#155724,color:#fff</code></pre>"},{"location":"concepts/platform-overview/#phase-1-structured-intelligence-ga","title":"Phase 1 \u2014 Structured intelligence (GA)","text":"<p>Upload recorded audio and receive structured insights: speaker-attributed transcripts, sentiment analysis, AI-generated summaries, and PII redaction. Delivered through a REST API and SaaS dashboard.</p> <p>Who it's for: customer support teams, compliance departments, sales enablement, HR, and healthcare providers who need to analyze recorded conversations at scale.</p>"},{"location":"concepts/platform-overview/#phase-2-real-time-analytics-beta","title":"Phase 2 \u2014 Real-time analytics (Beta)","text":"<p>Integrate with live audio streams to receive transcription, sentiment scoring, and behavioral alerts during an ongoing conversation with latency under 2 seconds. Supervisors can monitor calls live and intervene in real time.</p> <p>Who it's for: call center supervisors, quality assurance teams, and compliance officers who need live visibility into conversations.</p>"},{"location":"concepts/platform-overview/#phase-3-autonomous-voice-agents-planned","title":"Phase 3 \u2014 Autonomous voice agents (Planned)","text":"<p>Deploy AI voice agents capable of managing full conversations independently: understanding context, responding dynamically, executing tasks, and escalating to humans when required. Built on accumulated datasets from Phases 1 and 2.</p> <p>Who it's for: organizations looking to automate high-volume, structured voice interactions in support, sales, or HR workflows.</p>"},{"location":"concepts/platform-overview/#target-industries","title":"Target industries","text":"Industry Primary use case Customer support Call quality monitoring, sentiment-based escalation, agent coaching Sales Conversation intelligence, objection detection, deal risk signals Human resources Interview analysis, candidate sentiment, compliance documentation Healthcare Patient interaction documentation, compliance audit trails Financial services Regulatory compliance, call archiving, risk detection"},{"location":"concepts/platform-overview/#platform-architecture","title":"Platform architecture","text":"<p>NovaPulse is built on a cloud-native, multi-tenant architecture with four core layers:</p> <ul> <li>Ingestion layer \u2014 Accepts audio via REST API or real-time stream</li> <li>AI processing layer \u2014 Transcription, diarization, NLP, and summarization</li> <li>Storage layer \u2014 Encrypted audio storage and vector-indexed transcript store</li> <li>Delivery layer \u2014 REST API, webhooks, and dashboard</li> </ul> <p>See System Architecture for a full technical breakdown.</p>"},{"location":"concepts/platform-overview/#key-design-principles","title":"Key design principles","text":"<p>Privacy by design. PII detection and redaction run automatically on every transcript. Data is encrypted in transit and at rest. GDPR-ready by default.</p> <p>API-first. Every NovaPulse capability is accessible via REST API. The dashboard is built on the same API available to developers.</p> <p>Phased value delivery. Each phase delivers immediate business value independently. Organizations don't need to wait for Phase 3 to benefit from Phase 1.</p>"},{"location":"concepts/platform-overview/#related","title":"Related","text":"<ul> <li>Getting Started tutorial</li> <li>Vector Search \u2014 How NovaPulse enables semantic search</li> <li>NLP Capabilities \u2014 The AI models powering NovaPulse</li> <li>API Reference</li> </ul>"},{"location":"concepts/rag-pipeline/","title":"RAG Pipeline","text":"<p>Retrieval-Augmented Generation (RAG) is the architecture that powers NovaPulse's AI-driven insights. It combines the recall capability of vector search with the reasoning capability of a large language model (LLM) to answer natural language questions about your conversation data.</p>"},{"location":"concepts/rag-pipeline/#why-rag-not-a-standalone-llm","title":"Why RAG, not a standalone LLM","text":"<p>A standalone LLM cannot answer questions about your data:</p> <ul> <li>It was trained on public data up to a cutoff date</li> <li>It has no access to your call transcripts</li> <li>It will generate plausible-sounding but wrong answers (hallucinations)</li> </ul> <p>RAG solves this by giving the LLM real, current context from your own data before it generates a response.</p>"},{"location":"concepts/rag-pipeline/#the-three-step-rag-flow","title":"The three-step RAG flow","text":"<pre><code>flowchart LR\n  A[User query] --&gt; B[Embed query into vector]\n  B --&gt; C[Search transcript vector store]\n  C --&gt; D[Retrieve top-k relevant segments]\n  D --&gt; E[Augment LLM prompt with context]\n  E --&gt; F[LLM generates grounded response]\n  F --&gt; G[Response with source citations]\n\n  style A fill:#1B4F8A,color:#fff\n  style G fill:#155724,color:#fff</code></pre>"},{"location":"concepts/rag-pipeline/#step-1-retrieve","title":"Step 1: Retrieve","text":"<p>The user's question is converted to a vector using NovaPulse's embedding model. A kNN search finds the transcript segments most semantically similar to the question.</p>"},{"location":"concepts/rag-pipeline/#step-2-augment","title":"Step 2: Augment","text":"<p>The retrieved segments are injected into the LLM prompt:</p> <pre><code>Context from call transcripts:\n[Segment 1: CALL-0042, timestamp 4:12] Customer: This charge is completely\nunexpected. I was never told about the $49 monthly fee...\n\n[Segment 2: CALL-0089, timestamp 2:31] Customer: Why is my bill so much\nhigher than last month? Nobody explained the price changes...\n\nBased on the above context, answer: What billing concerns are customers\nraising most frequently this week?\n</code></pre>"},{"location":"concepts/rag-pipeline/#step-3-generate","title":"Step 3: Generate","text":"<p>The LLM generates a response grounded in the actual transcript data, with references to the source calls. NovaPulse includes citation links so supervisors can navigate directly to the relevant conversation.</p>"},{"location":"concepts/rag-pipeline/#novapulses-vector-store","title":"NovaPulse's vector store","text":"<p>NovaPulse stores all transcript segment embeddings in a high-performance vector database indexed for approximate nearest neighbor (ANN) search. This enables sub-second semantic search across millions of transcript segments with configurable recall-latency tradeoffs.</p>"},{"location":"concepts/rag-pipeline/#related","title":"Related","text":"<ul> <li>Vector Search \u2014 Embedding and kNN search explained</li> <li>NLP Capabilities \u2014 How transcripts are generated</li> <li>System Architecture</li> </ul>"},{"location":"concepts/vector-search/","title":"Vector Search in NovaPulse","text":"<p>Traditional keyword search looks for exact word matches. When a supervisor searches call transcripts for \"cancellation\", they will miss transcripts where a customer said \"I want to leave\" or \"thinking about switching\". For voice analytics, this is a critical limitation.</p> <p>NovaPulse uses vector search \u2014 also called semantic search \u2014 to find content based on meaning rather than exact words.</p>"},{"location":"concepts/vector-search/#how-vector-embeddings-work","title":"How vector embeddings work","text":"<p>When NovaPulse processes a transcript, each segment of speech is passed through an embedding model that converts the text into a dense vector: a list of numbers that encodes the semantic meaning of the text.</p> <pre><code>\"I want to cancel my subscription\"  \u2192  [0.23, -0.87, 0.44, 0.91, ...]\n\"thinking about switching providers\" \u2192  [0.21, -0.89, 0.46, 0.88, ...]  \u2190 similar\n\"great experience today, thank you\"  \u2192  [-0.91, 0.33, -0.67, 0.12, ...] \u2190 different\n</code></pre> <p>Texts with similar meaning produce vectors that are mathematically close together. Distance between vectors is measured using cosine similarity.</p>"},{"location":"concepts/vector-search/#semantic-search-in-novapulse","title":"Semantic search in NovaPulse","text":"<p>When you use the Insights API to search conversations, NovaPulse:</p> <ol> <li>Converts your query into a vector using the same embedding model</li> <li>Performs a k-nearest neighbor (kNN) search across all stored transcript vectors</li> <li>Returns the conversations whose vectors are closest to your query vector</li> <li>Ranks results by semantic similarity, not keyword frequency</li> </ol>"},{"location":"concepts/vector-search/#example","title":"Example","text":"<p>A support manager queries:</p> <pre><code>\"calls where customers expressed frustration about billing\"\n</code></pre> <p>NovaPulse returns relevant calls even if they contain none of those exact words \u2014 including transcripts where customers said \"this charge makes no sense\", \"I'm really annoyed about this invoice\", or \"nobody explained the fees to me\".</p>"},{"location":"concepts/vector-search/#hybrid-search","title":"Hybrid search","text":"<p>For queries involving exact terms \u2014 product names, error codes, or precise phrases \u2014 pure semantic search can underperform. NovaPulse supports hybrid search that combines:</p> Method Strengths BM25 (keyword) Exact term matching, product names, error codes kNN (semantic) Concept matching, synonyms, conversational language Hybrid (RRF) Best results for most real-world queries <p>Results from both methods are merged using Reciprocal Rank Fusion (RRF), which combines rankings without requiring score normalization.</p>"},{"location":"concepts/vector-search/#related-concepts","title":"Related concepts","text":"<ul> <li>RAG Pipeline \u2014 How NovaPulse uses retrieval for AI answers</li> <li>NLP Capabilities \u2014 Transcription, diarization, sentiment</li> <li>Glossary \u2014 Definitions of all AI terms</li> </ul>"},{"location":"tutorials/getting-started/","title":"Getting started","text":"<p>This tutorial walks you through uploading an audio file to NovaPulse and retrieving a transcript with sentiment analysis. By the end, you will have made your first successful API request and received structured insights from a real audio file.</p> <p>Time to complete: approximately 10 minutes</p>"},{"location":"tutorials/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin:</p> <ul> <li> A NovaPulse account \u2014 sign up free</li> <li> An API key \u2014 see Authentication</li> <li> cURL installed (included on Windows 10+ and macOS)</li> <li> An audio file in MP3 or WAV format (minimum 10 seconds)</li> </ul>"},{"location":"tutorials/getting-started/#step-1-set-your-api-key-as-an-environment-variable","title":"Step 1: Set your API key as an environment variable","text":"<p>Store your key as an environment variable to avoid hardcoding it in commands. Open your terminal and run:</p> macOS / LinuxWindows (PowerShell)Windows (Command Prompt) <pre><code>export NOVAPULSE_API_KEY=nvp_live_YOUR_KEY_HERE\n</code></pre> <pre><code>$env:NOVAPULSE_API_KEY = 'nvp_live_YOUR_KEY_HERE'\n</code></pre> <pre><code>set NOVAPULSE_API_KEY=nvp_live_YOUR_KEY_HERE\n</code></pre>"},{"location":"tutorials/getting-started/#step-2-upload-an-audio-file","title":"Step 2: Upload an audio file","text":"<p>Upload your file to the ingestion endpoint. Replace <code>call.mp3</code> with the actual path to your audio file.</p> <pre><code>curl -X POST https://api.novapulse.io/v1/audio/ingest \\\n  -H \"Authorization: Bearer $NOVAPULSE_API_KEY\" \\\n  -F 'file=@call.mp3' \\\n  -F 'pipeline=full-analysis'\n</code></pre> <p>You should see a response like this:</p> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"status\": \"queued\",\n  \"created_at\": \"2025-04-15T14:32:00Z\",\n  \"estimated_completion\": \"2025-04-15T14:34:00Z\"\n}\n</code></pre> <p>Save the <code>job_id</code> value, you will use it in the next steps.</p>"},{"location":"tutorials/getting-started/#step-3-check-processing-status","title":"Step 3: Check processing status","text":"<p>Audio processing is asynchronous. Poll the job status endpoint until <code>status</code> is <code>completed</code>:</p> <pre><code>curl https://api.novapulse.io/v1/jobs/job_9f3c2a1b4e7d \\\n  -H \"Authorization: Bearer $NOVAPULSE_API_KEY\"\n</code></pre> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"status\": \"completed\",\n  \"pipeline\": \"full-analysis\",\n  \"completed_at\": \"2025-04-15T14:33:47Z\"\n}\n</code></pre> <p>Tip</p> <p>For production integrations, use a webhook instead of polling. Pass <code>webhook_url</code> in your upload request and NovaPulse will POST a notification to your endpoint when processing completes.</p>"},{"location":"tutorials/getting-started/#step-4-retrieve-the-transcript","title":"Step 4: Retrieve the transcript","text":"<pre><code>curl https://api.novapulse.io/v1/transcriptions/job_9f3c2a1b4e7d \\\n  -H \"Authorization: Bearer $NOVAPULSE_API_KEY\"\n</code></pre> <p>The response includes a speaker-attributed transcript:</p> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"language\": \"en-US\",\n  \"duration_seconds\": 312,\n  \"segments\": [\n    {\n      \"speaker\": \"Agent\",\n      \"start\": 0.0,\n      \"end\": 4.2,\n      \"text\": \"Thank you for calling support. How can I help you today?\"\n    },\n    {\n      \"speaker\": \"Customer\",\n      \"start\": 4.5,\n      \"end\": 11.8,\n      \"text\": \"I need to cancel my subscription. The pricing just doesn't work for us.\"\n    }\n  ]\n}\n</code></pre>"},{"location":"tutorials/getting-started/#step-5-retrieve-sentiment-analysis","title":"Step 5: Retrieve sentiment analysis","text":"<pre><code>curl https://api.novapulse.io/v1/insights/job_9f3c2a1b4e7d?type=sentiment \\\n  -H \"Authorization: Bearer $NOVAPULSE_API_KEY\"\n</code></pre> <pre><code>{\n  \"job_id\": \"job_9f3c2a1b4e7d\",\n  \"overall_sentiment\": \"negative\",\n  \"sentiment_score\": -0.68,\n  \"segments\": [\n    { \"speaker\": \"Customer\", \"start\": 4.5, \"sentiment\": \"negative\", \"score\": -0.82 },\n    { \"speaker\": \"Agent\",    \"start\": 12.1, \"sentiment\": \"neutral\",  \"score\": 0.05 }\n  ]\n}\n</code></pre>"},{"location":"tutorials/getting-started/#what-you-built","title":"What you built","text":"<ul> <li> Uploaded an audio file using the Ingestion API</li> <li> Polled job status and confirmed completion</li> <li> Retrieved a speaker-attributed transcript</li> <li> Retrieved per-segment sentiment analysis</li> </ul>"},{"location":"tutorials/getting-started/#next-steps","title":"Next steps","text":"<ul> <li>Upload &amp; Analyze Audio tutorial \u2014 batch processing   and metadata strategies</li> <li>Sentiment Analysis API reference</li> <li>Vector Search concepts \u2014 how to query by meaning</li> </ul>"}]}